# 🕷️ Web Crawler using Streamlit

This project is a simple web crawler built with Python and Streamlit. It allows users to input a starting URL, crawl linked pages up to a defined limit, extract all `<h1>` titles from the pages, and view or download the data in CSV format.

---

## 🚀 Features

- 🌐 User-defined start URL
- 🔗 Follows hyperlinks recursively
- 📄 Extracts `<h1>` titles from each page
- 📉 Progress tracking with a progress bar
- 📥 CSV download of extracted titles
- 🎛️ Adjustable max page limit via slider
- 🧪 Built-in browser and test-safe design
- 🖥️ Deployed using Streamlit with a responsive UI

---

## 📸 Demo

![Web Crawler UI Screenshot](screenshot.png) <!-- Replace with actual screenshot file name -->

---

## 🔧 Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/yourusername/web-crawler-streamlit.git
   cd web-crawler-streamlit

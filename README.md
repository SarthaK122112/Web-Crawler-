ğŸ¯ Focused Dark Pattern Web Crawler
An asynchronous, NLP-driven web crawler built with Python and Streamlit that selectively crawls topic-relevant web pages, detects potential dark patterns, and extracts meaningful content. The crawler uses spaCy semantic similarity to focus only on relevant pages, ensuring efficient and targeted crawling.

ğŸš€ Features
ğŸ” Topic-Focused Crawling using NLP similarity scoring
ğŸ§  spaCy-powered Semantic Filtering (en_core_web_md)
ğŸš¨ Dark Pattern Detection via keyword and CSS class analysis
ğŸ•·ï¸ Asynchronous Crawling with concurrency control (Aiohttp + Asyncio)
ğŸ¤– robots.txt Compliance
ğŸ“Š Real-time Progress Tracking
ğŸ“ CSV Export for extracted titles and dark pattern findings
ğŸ–¥ï¸ Interactive UI built with Streamlit

ğŸ› ï¸ Tech Stack
Language: Python
Framework: Streamlit
Web Crawling: Aiohttp, Asyncio
HTML Parsing: BeautifulSoup
NLP: spaCy (en_core_web_md)
Data Handling: Pandas, CSV
Others: Regex, urllib

ğŸ§© How It Works
User provides a start URL and target topic.
The crawler converts the topic into a spaCy document.
Each visited page is:
   Checked for semantic relevance using cosine similarity.
   Parsed only if it exceeds a relevance threshold.
Relevant pages are scanned for:
   <h1> titles
   Dark patterns (e.g., urgency phrases, hidden costs).
   Only relevant links are added to the crawl queue.
   Results are displayed live and downloadable as CSV files.

ğŸš¨ Dark Pattern Detection
The crawler identifies potential dark patterns using:
Keyword-based patterns
(e.g., â€œonly 2 left in stockâ€, â€œlimited time offerâ€)
Suspicious CSS classes
(e.g., confirm-shame, hidden-cost, high-demand)
Each finding includes:
   URL
   Pattern type
   Matched keyword or CSS class
   Context (when available)

ğŸ“„ Output
H1 Titles CSV â€“ Extracted from topic-relevant pages
Dark Patterns CSV â€“ Potential dark patterns with context
Live Tables displayed in the Streamlit UI

ğŸ“Œ Use Cases
Dark pattern research & analysis
Ethical UX auditing
Web scraping with NLP filtering
Academic and research projects
Responsible web crawling demonstrations
